{
  "hash": "301cb933b6ec59c9daac5f56ebeaac06",
  "result": {
    "markdown": "---\ntitle: \"Kontrola stavových kódů většího počtu URL v R\"\ndescription: |\n  Potřeboval jsem rychle zkontrolovat stavové kódy HTTP dlouhého seznamu URL. Přitom jsem si vyzkoušel balíček furrr na paralelní zpracování a moc se mi zalíbil.\nauthor: Marek Prokop\ndate: \"2022-04-09\"\n---\n\n\n\n\nKlient nedávno měnil CMS i doménu webu, došlo ke změně hodně URL, klasický zmatek, jako v těhle případech vždy. Asi měsíc po změně se ukázalo, že se něco nepovedlo a URL starého webu, které měly být přesměrované na nový web, nyní vrací chybu. Navíc jsou některé z nich ještě stále ve výsledcích hledání Googlu.\n\nVytáhli jsme tedy ze Search Console starého webu URL všech stránek, které se od změny domény alespoň jednou zobrazily, a mým úkolem bylo rychle zkontrolovat, jaké HTTP kódy vracejí. Konkrétně mě zajímalo, která URL fungují (vrací HTTP 200), neexistují (vrací chybu 404 nebo jinou 4xx), nebo na serveru způsobí nějakou chybu (kódy 5xx).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(furrr)\nlibrary(rvest)\nlibrary(httr)\nlibrary(tictoc)\n```\n:::\n\n\nPro potřeby tohoto zápisku jsem skutečná URL nahradil odkazy z úvodní stránky Wikipedie, ke kterým jsem navíc přidal 10 náhodných adres, aby mi to ukázalo nějaké chyby. Na principu to nic nemění. Ty odkazy jsem získal takhle:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_url <- \"https://www.wikipedia.org/\"\n\nurls <- read_html(start_url) |>\n  html_elements(\"a\") |>\n  html_attr(\"href\") |>\n  xml2::url_absolute(start_url) |> \n  c(paste0(start_url, stringi::stri_rand_strings(10, 15)))\n```\n:::\n\n\nJedná se o 340 adres, a náhodný vzorek deseti z nich vypadá takhle:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample(urls, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"https://om.wikipedia.org/\"                \n [2] \"https://www.wikipedia.org/f5NHoRoonRkdi0T\"\n [3] \"https://xh.wikipedia.org/\"                \n [4] \"https://os.wikipedia.org/\"                \n [5] \"https://hsb.wikipedia.org/\"               \n [6] \"https://sah.wikipedia.org/\"               \n [7] \"https://sq.wikipedia.org/\"                \n [8] \"https://ga.wikipedia.org/\"                \n [9] \"https://sm.wikipedia.org/\"                \n[10] \"https://sw.wikipedia.org/\"                \n```\n:::\n:::\n\n\n## Kontrola jednoho URL\n\nPro kontrolu jednoho URL si připravím funkci `check_url`. Ta zadané URL zkontroluje HTTP požadavkem HEAD (z balíčku [httr](https://httr.r-lib.org/)), zjistí návratový kód a vrátí tibble s původním URL, výsledným URL (z toho se pozná případné přesměrování) a kódem odpovědi. Pro požadavek se také nastaví timeout v sekundách. Pokud server do této doby neodpoví, místo výsledného HTTP kódu se zapíše `NA`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_url <- function(url, timeout) {\n  resp <- try(HEAD(url, timeout(timeout)), silent = TRUE)\n  if (class(resp) == \"try-error\") {\n    status <- NA_integer_\n    dest_url <- NA_character_\n  } else {\n    status <- resp$status_code\n    dest_url <- resp$url\n  }\n  tibble(url, dest_url, status)\n}\n```\n:::\n\n\nVyzkouším, zda funkce funguje s platným (ale přesměrovaným) URL.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_url(\"https://wikipedia.org/\", 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  url                    dest_url                   status\n  <chr>                  <chr>                       <int>\n1 https://wikipedia.org/ https://www.wikipedia.org/    200\n```\n:::\n:::\n\n\nA raději i s neplatným:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_url(\"https://www.wikipedia.org/iououoiuoiuoiu\", 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  url                                      dest_url                       status\n  <chr>                                    <chr>                           <int>\n1 https://www.wikipedia.org/iououoiuoiuoiu https://en.wikipedia.org/iouo…    404\n```\n:::\n:::\n\n\n## Kontrola celého seznamu URL\n\nA teď již mohu pomocí funkce `map_dfr` z balíčku [purrr](https://purrr.tidyverse.org/) zkontrolovat celý seznam URL. Zároveň si budu pomocí funkcí `tic` a `toc` z balíčku [tictoc](http://collectivemedia.github.io/tictoc/) měřit, jak dlouho to celé trvá s timeoutem nastaveným na 0.5 sekundy. Reálně by byl potřeba vyšší timeout, např. 3 sekundy, ale Wikiepedia je docela rychlá a já chci ukázat výstup, ve kterém se některá URL v časovém limitu zkontrolovat nepodařilo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nstatus_codes <- urls |>\n  map_dfr(check_url, 0.5)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n48.37 sec elapsed\n```\n:::\n:::\n\n\nTrvá to docela dlouho a mohlo by to trvat ještě déle, pokud by byl server pomalejší. Teoreticky až počet URL v seznamu krát timeout. Tak dlouho se mi čekat nechce.\n\nProto raději zkusím balíček [furrr](https://furrr.futureverse.org/), který nabízí obdobné funkce jako *purrr*, jenže paralelizované tak, aby využily víc jader a vláken procesoru. Natavím 6 vláken, takže načtení URL by mělo být skoro šestkrát rychlejší.\n\n### Zrychlení balíčkem *furrr*\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplan(multisession, workers = 6)\n\ntic()\nstatus_codes <- urls |>\n  future_map_dfr(check_url, 0.5)\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n9.94 sec elapsed\n```\n:::\n:::\n\n\nJo! Šestkrát rychlejší to sice není, ale i tak je zrychlení super. S tím už se pár tisíc URL zpracovat dá.\n\n## Zobrazení výsledků\n\nA zbývá se podívat na výsledky. Jsou v dataframu (tibble), takže stačí běžné funkce z balíčku [dplyr](https://dplyr.tidyverse.org/)\n\n### Souhrnný přehled\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstatus_codes |>\n  count(status, sort = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  status     n\n   <int> <int>\n1    200   329\n2    404    10\n3     NA     1\n```\n:::\n:::\n\n\n### Vadné URL\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstatus_codes |> \n  filter(status != 200)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 3\n   url                                       dest_url                     status\n   <chr>                                     <chr>                         <int>\n 1 https://www.wikipedia.org/HmPsw2WtYSxSgZ6 https://en.wikipedia.org/Hm…    404\n 2 https://www.wikipedia.org/tF2KxtgdzehXaH9 https://en.wikipedia.org/tF…    404\n 3 https://www.wikipedia.org/xtgn1TlDJE8PPM9 https://en.wikipedia.org/xt…    404\n 4 https://www.wikipedia.org/8ESGr2Rn7YC7ktN https://en.wikipedia.org/8E…    404\n 5 https://www.wikipedia.org/f5NHoRoonRkdi0T https://en.wikipedia.org/f5…    404\n 6 https://www.wikipedia.org/DNbL6FfPm6QztsA https://en.wikipedia.org/DN…    404\n 7 https://www.wikipedia.org/8eLeJBm5SVbKUxT https://en.wikipedia.org/8e…    404\n 8 https://www.wikipedia.org/tubP9vI3wi8YxaP https://en.wikipedia.org/tu…    404\n 9 https://www.wikipedia.org/eJJDMz958gctfjW https://en.wikipedia.org/eJ…    404\n10 https://www.wikipedia.org/eomyRJP0BqEE4Fj https://en.wikipedia.org/eo…    404\n```\n:::\n:::\n\n\n### Timeouty\n\nA pokud tam jsou i adresy, které nestihly timeout, pak jdou vypsat takhle:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstatus_codes |> \n  filter(is.na(status))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  url                                                             dest_…¹ status\n  <chr>                                                           <chr>    <int>\n1 https://itunes.apple.com/app/apple-store/id324715238?pt=208305… <NA>        NA\n# … with abbreviated variable name ¹​dest_url\n```\n:::\n:::\n\n\nPřípadně je můžu znovu projet s vyšším timeoutem, třeba takhle:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstatus_codes |> \n  filter(is.na(status)) |> \n  pull(url) |> \n  future_map_dfr(check_url, 2)\n```\n:::\n\n\nA to je všechno :-)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}