[
  {
    "path": "posts/2022-04-09-cistim-search-consoli/",
    "title": "Čístím Search Consoli od zbytečných webů",
    "description": "Jako každý SEO konzultantant mám v Google Search Consoli plno webů, ke kterým už nemám přístup, nebo které už dlouho nefungují. Napsal jsem si skript v R, který je odstraní.",
    "author": [
      {
        "name": "Marek Prokop",
        "url": {}
      }
    ],
    "date": "2022-04-10",
    "categories": [],
    "contents": "\r\nPříprava\r\nSkriptu stačí tyhle dva balíčky.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(searchConsoleR)\r\n\r\n\r\n\r\nA klasická autorizace do Search Console. Kdybych neměl svůj Google e-mail uložený v systémové proměnné, musel bych ho napsat do parametru email přímo.\r\n\r\n\r\nscr_auth(email = Sys.getenv(\"MY_GOOGLE_ACCOUNT\"))\r\n\r\n\r\n\r\nFunkcí list_websites načtu všechny weby, které v Search Consoli mám, a uložím si je do objektu websites.\r\n\r\n\r\nwebsites <- list_websites()\r\n\r\n\r\n\r\nSeznam vypadá nějak takhle, jen jsem konkrétní weby ze své Search Console anonymizoval, abych mohl výstup publikovat. Když vynechám poslední řádek, budou weby normálně vidět.\r\n\r\n\r\nwebsites |> \r\n  slice_sample(n = 10) |> \r\n  mutate(siteUrl = anonymize_site(siteUrl))\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"siteUrl\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"permissionLevel\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"sc-domain:anonymized.cz\",\"2\":\"siteFullUser\"},{\"1\":\"https://anonymized.eu/\",\"2\":\"siteFullUser\"},{\"1\":\"https://anonymized.cz/\",\"2\":\"siteRestrictedUser\"},{\"1\":\"https://anonymized.cz/\",\"2\":\"siteFullUser\"},{\"1\":\"https://anonymized.se/\",\"2\":\"siteFullUser\"},{\"1\":\"http://anonymized.cz/\",\"2\":\"siteRestrictedUser\"},{\"1\":\"sc-domain:anonymized.com\",\"2\":\"siteOwner\"},{\"1\":\"http://anonymized.cz/\",\"2\":\"siteOwner\"},{\"1\":\"sc-domain:anonymized.uk\",\"2\":\"siteFullUser\"},{\"1\":\"https://anonymized.sk/\",\"2\":\"siteFullUser\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nNeautorizované weby\r\nDůležitý je sloupec permissionLevel. Mám v něm tyhle hodnoty:\r\n\r\n\r\nwebsites |> \r\n  count(permissionLevel)\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"permissionLevel\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"siteFullUser\",\"2\":\"61\"},{\"1\":\"siteOwner\",\"2\":\"31\"},{\"1\":\"siteRestrictedUser\",\"2\":\"9\"},{\"1\":\"siteUnverifiedUser\",\"2\":\"15\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nZbavit se chci webů, ke kterým nemám povolený přístup. Vypíšu si je a raději je pečlivě zkontroluju (samozřejmě až odstraním anonymizaci na posledním řádku).\r\n\r\n\r\nunverified_websites <- websites |> \r\n  filter(permissionLevel == \"siteUnverifiedUser\")\r\n\r\nunverified_websites |> \r\n  mutate(siteUrl = anonymize_site(siteUrl))\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"siteUrl\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"permissionLevel\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"sc-domain:anonymized.cz\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"https://anonymized.cz/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"https://anonymized.cz/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"https://anonymized.cz/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"https://anonymized.cz/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"http://anonymized.com/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"https://anonymized.cz/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"https://anonymized.cz/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"https://anonymized.com/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"http://anonymized.cz/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"http://anonymized.cz/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"https://anonymized.cz/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"https://anonymized.org/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"http://anonymized.cz/\",\"2\":\"siteUnverifiedUser\"},{\"1\":\"http://anonymized.cz/\",\"2\":\"siteUnverifiedUser\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nZe Search Console si je pak odstraním takto. Jen před tím přepíšu na prvním řádku FALSE na TRUE. Dal jsem to tam proto, abych si nechtěně nesmazal weby před tím, než si je zkontroluju.\r\n\r\n\r\nif (FALSE) {\r\n  unverified_websites |> \r\n    pull(siteUrl) |> \r\n    walk(delete_website)\r\n}\r\n\r\n\r\n\r\nKdyž to pustím, křičí to na mě nějaké warningy ohledně JSON. Asi je někde nějaká chybka, ale podle všeho ničemu nevadí a skript dělá to, co má. Každopádně si pak můžu ověřit, jestli už jsou všechny neverifikované weby pryč:\r\n\r\n\r\nlist_websites() |> \r\n  filter(permissionLevel == \"siteUnverifiedUser\")\r\n\r\n\r\n\r\nWeby bez dat\r\nKromě neutorizovaných webů se chci zbavit i těch, které už dlouho nemají žádná data.\r\nNejdřív si definuju funkci, která načte souhrnné metriky jednoho webu za poslední dva roky. K výsledku přidám do prvního sloupce i URL webu, abych ho poznal, až jich bude v tabulce víc.\r\n\r\n\r\nget_site_metrics <- function(site) {\r\n  search_analytics(\r\n    siteURL = site, \r\n    startDate = Sys.Date() - 365 * 2, \r\n    endDate = Sys.Date()\r\n  ) |> \r\n    add_column(site = site, .before = 1)\r\n}\r\n\r\n\r\n\r\nOvěřím, zda funkce funguje.\r\n\r\n\r\nget_site_metrics(\"http://www.marekp.cz/\")\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"site\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"clicks\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"impressions\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"ctr\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"position\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"http://www.marekp.cz/\",\"2\":\"2837\",\"3\":\"51402\",\"4\":\"0.0551924\",\"5\":\"9.855045\",\"_rn_\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nFunguje, takže ji mohu pomocí funkce map_dfr z balíčku purrr aplikovat na celý seznam webů, ke kterým mám autorizovaný přístup. S více weby to nějakou chvíli poběží.\r\n\r\n\r\nall_site_metrics <- websites |> \r\n  filter(permissionLevel != \"siteUnverifiedUser\") |> \r\n  pull(siteUrl) |> \r\n  map_dfr(get_site_metrics)\r\n\r\n\r\n\r\nA teď už jen vyfiltruju a zobrazím (opět anonymizovaně) weby, které nemají žádné imprese.\r\n\r\n\r\nall_site_metrics |> \r\n  filter(impressions == 0) |> \r\n  mutate(site = anonymize_site(site))\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"site\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"clicks\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"impressions\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"ctr\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"position\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"https://anonymized.cz/\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"},{\"1\":\"https://anonymized.com/\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"},{\"1\":\"http://anonymized.com/\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"},{\"1\":\"https://anonymized.cz/\",\"2\":\"0\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nPokud je chci ze Search Console odebrat, udělám to podle návodu pro neautorizované weby výše.\r\nA to je všechno :-)\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-04-10T11:12:51+02:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-04-09-kontrola-http-kodu/",
    "title": "Kontrola stavových kódů většího počtu URL v R",
    "description": "Potřeboval jsem rychle zkontrolovat stavové kódy HTTP dlouhého seznamu URL. Přitom jsem si vyzkoušel balíček furrr na paralelní zpracování a moc se mi zalíbil.",
    "author": [
      {
        "name": "Marek Prokop",
        "url": {}
      }
    ],
    "date": "2022-04-09",
    "categories": [],
    "contents": "\r\nKlient nedávno měnil CMS i doménu webu, došlo ke změně hodně URL, klasický zmatek, jako v těhle případech vždy. Asi měsíc po změně se ukázalo, že se něco nepovedlo a URL starého webu, které měly být přesměrované na nový web, nyní vrací chybu. Navíc jsou některé z nich ještě stále ve výsledcích hledání Googlu.\r\nVytáhli jsme tedy ze Search Console starého webu URL všech stránek, které se od změny domény alespoň jednou zobrazily, a mým úkolem bylo rychle zkontrolovat, jaké HTTP kódy vracejí. Konkrétně mě zajímalo, která URL fungují (vrací HTTP 200), neexistují (vrací chybu 404 nebo jinou 4xx), nebo na serveru způsobí nějakou chybu (kódy 5xx).\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(furrr)\r\nlibrary(rvest)\r\nlibrary(httr)\r\nlibrary(tictoc)\r\n\r\n\r\n\r\nPro potřeby tohoto zápisku jsem skutečná URL nahradil odkazy z úvodní stránky Wikipedie, ke kterým jsem navíc přidal 10 náhodných adres, aby mi to ukázalo nějaké chyby. Na principu to nic nemění. Ty odkazy jsem získal takhle:\r\n\r\n\r\nstart_url <- \"https://www.wikipedia.org/\"\r\n\r\nurls <- read_html(start_url) |>\r\n  html_elements(\"a\") |>\r\n  html_attr(\"href\") |>\r\n  xml2::url_absolute(start_url) |> \r\n  c(paste0(start_url, stringi::stri_rand_strings(10, 15)))\r\n\r\n\r\n\r\nJedná se o 337 adres, a náhodný vzorek deseti z nich vypadá takhle:\r\n\r\n\r\nsample(urls, 10)\r\n\r\n\r\n [1] \"https://pag.wikipedia.org/\"               \r\n [2] \"https://www.wikipedia.org/tubP9vI3wi8YxaP\"\r\n [3] \"https://ak.wikipedia.org/\"                \r\n [4] \"https://ht.wikipedia.org/\"                \r\n [5] \"https://ilo.wikipedia.org/\"               \r\n [6] \"https://si.wikipedia.org/\"                \r\n [7] \"https://su.wikipedia.org/\"                \r\n [8] \"https://gd.wikipedia.org/\"                \r\n [9] \"https://trv.wikipedia.org/\"               \r\n[10] \"https://vec.wikipedia.org/\"               \r\n\r\nKontrola jednoho URL\r\nPro kontrolu jednoho URL si připravím funkci check_url. Ta zadané URL zkontroluje HTTP požadavkem HEAD (z balíčku httr), zjistí návratový kód a vrátí tibble s původním URL, výsledným URL (z toho se pozná případné přesměrování) a kódem odpovědi. Pro požadavek se také nastaví timeout v sekundách. Pokud server do této doby neodpoví, místo výsledného HTTP kódu se zapíše NA.\r\n\r\n\r\ncheck_url <- function(url, timeout) {\r\n  resp <- try(HEAD(url, timeout(timeout)), silent = TRUE)\r\n  if (class(resp) == \"try-error\") {\r\n    status <- NA_integer_\r\n    dest_url <- NA_character_\r\n  } else {\r\n    status <- resp$status_code\r\n    dest_url <- resp$url\r\n  }\r\n  tibble(url, dest_url, status)\r\n}\r\n\r\n\r\n\r\nVyzkouším, zda funkce funguje s platným (ale přesměrovaným) URL.\r\n\r\n\r\ncheck_url(\"https://wikipedia.org/\", 1)\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"url\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"dest_url\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"status\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"https://wikipedia.org/\",\"2\":\"https://www.wikipedia.org/\",\"3\":\"200\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nA raději i s neplatným:\r\n\r\n\r\ncheck_url(\"https://www.wikipedia.org/iououoiuoiuoiu\", 1)\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"url\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"dest_url\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"status\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"https://www.wikipedia.org/iououoiuoiuoiu\",\"2\":\"https://en.wikipedia.org/iououoiuoiuoiu\",\"3\":\"404\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nKontrola celého seznamu URL\r\nA teď již mohu pomocí funkce map_dfr z balíčku purrr zkontrolovat celý seznam URL. Zároveň si budu pomocí funkcí tic a toc z balíčku tictoc měřit, jak dlouho to celé trvá s timeoutem nastaveným na 0.5 sekundy. Reálně by byl potřeba vyšší timeout, např. 3 sekundy, ale Wikiepedia je docela rychlá a já chci ukázat výstup, ve kterém se některá URL v časovém limitu zkontrolovat nepodařilo.\r\n\r\n\r\ntic()\r\nstatus_codes <- urls |>\r\n  map_dfr(check_url, 0.5)\r\ntoc()\r\n\r\n\r\n60.52 sec elapsed\r\n\r\nTrvá to docela dlouho a mohlo by to trvat ještě déle, pokud by byl server pomalejší. Teoreticky až počet URL v seznamu krát timeout. Tak dlouho se mi čekat nechce.\r\nProto raději zkusím balíček furrr, který nabízí obdobné funkce jako purrr, jenže paralelizované tak, aby využily víc jader a vláken procesoru. Natavím 6 vláken, takže načtení URL by mělo být skoro šestkrát rychlejší.\r\nZrychlení balíčkem furrr\r\n\r\n\r\nplan(multisession, workers = 6)\r\n\r\ntic()\r\nstatus_codes <- urls |>\r\n  future_map_dfr(check_url, 0.5)\r\ntoc()\r\n\r\n\r\n13.34 sec elapsed\r\n\r\nJo! Šestkrát rychlejší to sice není, ale i tak je zrychlení super. S tím už se pár tisíc URL zpracovat dá.\r\nZobrazení výsledků\r\nA zbývá se podívat na výsledky. Jsou v dataframu (tibble), takže stačí běžné funkce z balíčku dplyr\r\nSouhrnný přehled\r\n\r\n\r\nstatus_codes |>\r\n  count(status, sort = TRUE)\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"status\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"200\",\"2\":\"324\"},{\"1\":\"404\",\"2\":\"10\"},{\"1\":\"NA\",\"2\":\"3\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nVadné URL\r\n\r\n\r\nstatus_codes |> \r\n  filter(status != 200)\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"url\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"dest_url\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"status\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"https://www.wikipedia.org/HmPsw2WtYSxSgZ6\",\"2\":\"https://en.wikipedia.org/HmPsw2WtYSxSgZ6\",\"3\":\"404\"},{\"1\":\"https://www.wikipedia.org/tF2KxtgdzehXaH9\",\"2\":\"https://en.wikipedia.org/tF2KxtgdzehXaH9\",\"3\":\"404\"},{\"1\":\"https://www.wikipedia.org/xtgn1TlDJE8PPM9\",\"2\":\"https://en.wikipedia.org/xtgn1TlDJE8PPM9\",\"3\":\"404\"},{\"1\":\"https://www.wikipedia.org/8ESGr2Rn7YC7ktN\",\"2\":\"https://en.wikipedia.org/8ESGr2Rn7YC7ktN\",\"3\":\"404\"},{\"1\":\"https://www.wikipedia.org/f5NHoRoonRkdi0T\",\"2\":\"https://en.wikipedia.org/f5NHoRoonRkdi0T\",\"3\":\"404\"},{\"1\":\"https://www.wikipedia.org/DNbL6FfPm6QztsA\",\"2\":\"https://en.wikipedia.org/DNbL6FfPm6QztsA\",\"3\":\"404\"},{\"1\":\"https://www.wikipedia.org/8eLeJBm5SVbKUxT\",\"2\":\"https://en.wikipedia.org/8eLeJBm5SVbKUxT\",\"3\":\"404\"},{\"1\":\"https://www.wikipedia.org/tubP9vI3wi8YxaP\",\"2\":\"https://en.wikipedia.org/tubP9vI3wi8YxaP\",\"3\":\"404\"},{\"1\":\"https://www.wikipedia.org/eJJDMz958gctfjW\",\"2\":\"https://en.wikipedia.org/eJJDMz958gctfjW\",\"3\":\"404\"},{\"1\":\"https://www.wikipedia.org/eomyRJP0BqEE4Fj\",\"2\":\"https://en.wikipedia.org/eomyRJP0BqEE4Fj\",\"3\":\"404\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nTimeouty\r\nA pokud tam jsou i adresy, které nestihly timeout, pak jdou vypsat takhle:\r\n\r\n\r\nstatus_codes |> \r\n  filter(is.na(status))\r\n\r\n\r\n\r\n\r\n{\"columns\":[{\"label\":[\"url\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"dest_url\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"status\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"https://ru.wikipedia.org/\",\"2\":\"NA\",\"3\":\"NA\"},{\"1\":\"https://sd.wikipedia.org/\",\"2\":\"NA\",\"3\":\"NA\"},{\"1\":\"https://ig.wikipedia.org/\",\"2\":\"NA\",\"3\":\"NA\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\r\n  \r\n\r\nPřípadně je můžu znovu projet s vyšším timeoutem, třeba takhle:\r\n\r\n\r\nstatus_codes |> \r\n  filter(is.na(status)) |> \r\n  pull(url) |> \r\n  future_map_dfr(check_url, 2)\r\n\r\n\r\n\r\nA to je všechno :-)\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2022-04-10T12:01:08+02:00",
    "input_file": {}
  }
]
