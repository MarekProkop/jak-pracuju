---
title: "Jak se zbavit azbuky, čínštiny apod."
description: |
  Do dat se občas dostane nechtěná ruština, čínština, řečtina, nebo jiný jazyk psaný nelatinkovým písmem. Tohle je rychlý návod, jak se takových textů pomocí regulárních výrazů zbavit, nebo je naopak najít.
author:
  - name: Marek Prokop
    affiliation: "[PROKOP software s.r.o.](https://www.prokopsw.cz/cs)"
date: 2022-05-01
df-print: kable
---

## Rychlý příklad

Mám tahle data:

```{r data}
#| label: data
#| message: false
library(tidyverse)

df <- tibble(
  text = c(
    "Praha - Střešovice",
    "Prague - Stresovice",
    "布拉格 - Střešovice",
    "Прага - Střešovice",
    "Πράγα - Střešovice"
  ), 
  jazyk = c("česky", "anglicky", "čínsky", "rusky", "řecky")
)

df
```

### Chci odstranit texty v azbuce

```{r}
df |> 
  filter(!str_detect(text, "[\\p{Cyrillic}]"))
```

### Chci odstranit texty v čínštině

```{r}
df |> 
  filter(!str_detect(text, "[\\p{Han}]"))
```

### Chci odstranit texty v řečtině

```{r}
df |> 
  filter(!str_detect(text, "[\\p{Greek}]"))
```

### Chci odstranit texty v čekmoli kromě latinky

To už je těžší. V předešlých případech jsem odstranil texty, které obsahovaly alespoň jeden znak z daného Unicode rozsahu, ale zde musím odstranit texty, které obsahují **jenom** znaky z daného rozsahu. Musím tedy zkombinovat tři část: 

- `{Latin}` -- latinkové znaky
- `{Punct}` -- interpunkce
- `\x20` -- mezera (může být napsaná i normálně, ale byla by blbě vidět)

```{r}
df |> 
  filter(str_detect(text, "^[\x20\\p{Punct}\\p{Latin}]+$"))
```

### Chci najít...

Samozřejmě to jde použít i pro hledání textů s určitými znaky.

Všechny v azbuce:

```{r}
df |> 
  filter(str_detect(text, "[\\p{Cyrillic}]"))
```

Všechny nelatinkové:

```{r}
df |> 
  filter(!str_detect(text, "^[\x20\\p{Punct}\\p{Latin}]+$"))
```
V případě potřeby něčeho speciálního poslouží [podrobný přehled Unicode v regulárních výrazech](https://www.regular-expressions.info/unicode.html).
