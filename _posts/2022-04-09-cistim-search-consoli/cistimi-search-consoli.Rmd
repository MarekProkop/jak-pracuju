---
title: "Čístím Search Consoli od zbytečných webů"
description: |
  Jako každý SEO konzultantant mám v Google Search Consoli plno webů, ke kterým už nemám přístup, nebo které už dlouho nefungují. Napsal jsem si skript v R, který je odstraní. 
author:
  - name: Marek Prokop
    affiliation: PROKOP software s.r.o.
    affiliation_url: https://www.prokopsw.cz/cs
date: 2022-04-10
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
paged_print <- function(x, ...) {
  knitr::knit_print(rmarkdown::paged_table(x), ...)
}

kable_print <- function(x, ...) {
  knitr::knit_print(knitr::kable(x), ...)
}

knitr::opts_chunk$set(
  echo = TRUE,
  render = paged_print
)
```

## Příprava

Skriptu stačí tyhle dva balíčky.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(searchConsoleR)
```

A klasická autorizace do Search Console. Kdybych neměl svůj Google e-mail uložený v systémové proměnné, musel bych ho napsat do parametru `email` přímo.

```{r}
scr_auth(email = Sys.getenv("MY_GOOGLE_ACCOUNT"))
```

```{r include=FALSE}
anonymize_site <- function(site) {
  str_replace(
    string = site,
    pattern = "(https?://|sc-domain:)[a-z0-9.-]+(\\..{2,4})(/?)(.*)?$", 
    replacement = "\\1anonymized\\2\\3")
}
```

Funkcí `list_websites` načtu všechny weby, které v Search Consoli mám, a uložím si je do objektu `websites`.

```{r}
websites <- list_websites()
```

Seznam vypadá nějak takhle, jen jsem konkrétní weby ze své Search Console anonymizoval, abych mohl výstup publikovat. Když vynechám poslední řádek, budou weby normálně vidět.

```{r}
websites |> 
  slice_sample(n = 10) |> 
  mutate(siteUrl = anonymize_site(siteUrl))
```

## Neautorizované weby

Důležitý je sloupec `permissionLevel`. Mám v něm tyhle hodnoty:

```{r}
websites |> 
  count(permissionLevel)
```

Zbavit se chci webů, ke kterým nemám povolený přístup. Vypíšu si je a raději je pečlivě zkontroluju (samozřejmě až odstraním anonymizaci na posledním řádku).

```{r}
unverified_websites <- websites |> 
  filter(permissionLevel == "siteUnverifiedUser")

unverified_websites |> 
  mutate(siteUrl = anonymize_site(siteUrl))
```

Ze Search Console si je pak odstraním takto. Jen před tím přepíšu na prvním řádku `FALSE` na `TRUE`. Dal jsem to tam proto, abych si nechtěně nesmazal weby před tím, než si je zkontroluju.

```{r echo=TRUE, eval=FALSE}
if (FALSE) {
  unverified_websites |> 
    pull(siteUrl) |> 
    walk(delete_website)
}
```

Když to pustím, křičí to na mě nějaké warningy ohledně JSON. Asi je někde nějaká chybka, ale podle všeho ničemu nevadí a skript dělá to, co má. Každopádně si pak můžu ověřit, jestli už jsou všechny neverifikované weby pryč:

```{r echo=TRUE, eval=FALSE}
list_websites() |> 
  filter(permissionLevel == "siteUnverifiedUser")
```

## Weby bez dat

Kromě neutorizovaných webů se chci zbavit i těch, které už dlouho nemají žádná data.

Nejdřív si definuju funkci, která načte souhrnné metriky jednoho webu za poslední dva roky. K výsledku přidám do prvního sloupce i URL webu, abych ho poznal, až jich bude v tabulce víc.

```{r}
get_site_metrics <- function(site) {
  search_analytics(
    siteURL = site, 
    startDate = Sys.Date() - 365 * 2, 
    endDate = Sys.Date()
  ) |> 
    add_column(site = site, .before = 1)
}
```

Ověřím, zda funkce funguje.

```{r}
get_site_metrics("http://www.marekp.cz/")
```

Funguje, takže ji mohu pomocí funkce `map_dfr` z balíčku *purrr* aplikovat na celý seznam webů, ke kterým mám autorizovaný přístup. S více weby to nějakou chvíli poběží.

```{r message=FALSE}
all_site_metrics <- websites |> 
  filter(permissionLevel != "siteUnverifiedUser") |> 
  pull(siteUrl) |> 
  map_dfr(get_site_metrics)
```

A teď už jen vyfiltruju a zobrazím (opět anonymizovaně) weby, které nemají žádné imprese.

```{r}
all_site_metrics |> 
  filter(impressions == 0) |> 
  mutate(site = anonymize_site(site))
```

Pokud je chci ze Search Console odebrat, udělám to podle návodu pro neautorizované weby výše.

A to je všechno :-)
